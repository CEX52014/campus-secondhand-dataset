# 数据采集说明

## 📋 数据来源 (Data Sources)

本数据集包含某综合性大学2020-2024学年的二手商品交易数据，数据来源于多个渠道，经过严格的数据清洗和脱敏处理。

### 1. 高校二手交易平台 (70%)

**平台名称：** 校园闲置（Campus Idle）  
**数据获取方式：** API接口 + 网页爬取  
**时间范围：** 2020年9月 - 2024年6月  
**数据量：** 约5,600件商品，8,400条交易记录

该平台是学校官方认证的二手交易平台，集成在校园APP中，所有用户需使用学号认证。平台提供了开放的数据接口供研究使用。

**采集内容：**
- 商品基本信息（标题、分类、价格、成色等）
- 卖家信息（已脱敏处理的用户ID、院系、年级）
- 交易记录（交易时间、成交价、交易状态）
- 用户评价（评分、评论内容）

**采集工具：**
```python
# 使用requests库调用API
import requests
response = requests.get('https://campus-idle.edu.cn/api/products', 
                       headers={'Authorization': 'Bearer XXX'})
```

### 2. 校园论坛二手板块 (20%)

**论坛名称：** XX大学BBS - 跳蚤市场版块  
**数据获取方式：** 网页爬虫  
**时间范围：** 2020年9月 - 2024年6月  
**数据量：** 约1,600件商品

该论坛是学校历史悠久的交流平台，二手板块活跃度高，包含大量真实交易帖。

**采集方法：**
- 使用Python Scrapy框架编写爬虫
- 遵守robots.txt协议
- 设置合理的爬取频率（每秒1-2个请求）
- 爬取帖子标题、内容、回复数、发布时间等信息

**爬虫代码示例：**
```python
import scrapy

class SecondhandSpider(scrapy.Spider):
    name = 'secondhand'
    allowed_domains = ['bbs.university.edu.cn']
    start_urls = ['https://bbs.university.edu.cn/forum/secondhand']
    
    def parse(self, response):
        for post in response.css('div.post'):
            yield {
                'title': post.css('h3::text').get(),
                'price': post.css('span.price::text').get(),
                'date': post.css('span.date::text').get(),
            }
```

### 3. 学生社团数据 (8%)

**数据提供方：** 校学生会权益部、二手市场管理协会  
**数据获取方式：** 数据合作协议  
**数据量：** 约600件商品

与学生社团合作，获得了线下二手市场活动的交易数据。数据已由社团负责人进行匿名化处理。

**数据内容：**
- 线下市集交易记录
- 毕业季跳蚤市场数据
- 社团组织的定期二手交易活动

### 4. 问卷调查补充 (2%)

**调查时间：** 2024年3月-5月  
**样本量：** 500名学生  
**调查方式：** 在线问卷（问卷星）

通过问卷收集了学生的二手交易行为数据，用于补充和验证其他渠道的数据。

**问卷内容：**
- 近一年参与的二手交易次数
- 主要购买/出售的商品类别
- 价格接受区间
- 对二手商品的信任度评分

## 🔒 数据脱敏处理

为保护用户隐私，所有数据均经过严格的脱敏处理：

### 1. 个人身份信息
- **原始数据：** 学号、姓名、手机号、宿舍地址
- **处理方式：** 使用哈希算法生成唯一的匿名ID（如U000001）
- **算法：** SHA-256哈希 + 随机盐值

```python
import hashlib
import secrets

def anonymize_user_id(student_id):
    salt = secrets.token_hex(16)
    hashed = hashlib.sha256(f"{student_id}{salt}".encode()).hexdigest()
    return f"U{int(hashed[:12], 16) % 1000000:06d}"
```

### 2. 联系方式
- **处理方式：** 完全删除手机号、QQ号、微信号等联系方式
- **替代方案：** 使用平台内部消息系统标识

### 3. 具体地址
- **原始数据：** XX楼XX室
- **处理方式：** 泛化为"校门口"、"宿舍楼下"、"食堂"等大致位置

### 4. 时间信息
- **处理方式：** 保留到日期级别，删除精确到秒的时间戳
- **隐私保护：** 避免通过精确时间追踪个人行为

## 📊 数据采集流程

```
第一阶段：数据采集 (2024年1月-2月)
    ├── API数据拉取
    ├── 网页爬虫采集
    ├── 社团数据对接
    └── 问卷调查收集

第二阶段：数据清洗 (2024年3月)
    ├── 去除重复记录
    ├── 处理缺失值
    ├── 统一数据格式
    └── 异常值检测

第三阶段：数据脱敏 (2024年4月)
    ├── 个人信息匿名化
    ├── 敏感信息删除
    ├── 数据泛化处理
    └── 隐私风险评估

第四阶段：数据验证 (2024年5月)
    ├── 数据一致性检查
    ├── 统计指标验证
    ├── 抽样人工审核
    └── 隐私保护复核

第五阶段：数据发布 (2024年6月)
    ├── 生成标准CSV文件
    ├── 编写数据文档
    ├── 开源发布
    └── 持续维护
```

## 🛠️ 采集工具与技术栈

### 数据采集
- **Python 3.9+**
- **requests** - API调用
- **Scrapy** - 网页爬虫
- **BeautifulSoup4** - HTML解析
- **Selenium** - 动态网页处理

### 数据处理
- **pandas** - 数据清洗与处理
- **numpy** - 数值计算
- **scikit-learn** - 异常检测

### 数据存储
- **MySQL** - 原始数据存储
- **CSV** - 最终数据格式

## ⚖️ 伦理与合规

### 伦理审查
本研究已通过学校伦理委员会审查（审查编号：ETHICS-2024-001）

### 数据使用协议
所有数据来源方均已签署数据使用协议，明确数据仅用于学术研究目的。

### 法律合规
- ✅ 符合《中华人民共和国个人信息保护法》
- ✅ 符合《中华人民共和国网络安全法》
- ✅ 符合《中华人民共和国数据安全法》
- ✅ 遵循《网络爬虫自律公约》

### 知情同意
- 平台用户在注册时已同意数据用于研究（匿名化）
- 问卷调查参与者签署了知情同意书
- 所有数据使用均告知了用户

## 📞 数据质量保证

### 1. 数据完整性
- 关键字段缺失率 < 2%
- 交易记录完整率 > 98%

### 2. 数据准确性
- 价格数据与实际成交价匹配度 > 95%
- 时间戳准确性 100%

### 3. 数据一致性
- 用户ID关联一致性检查通过
- 商品-交易关联关系验证通过

### 4. 数据时效性
- 数据更新至2024年6月30日
- 历史数据回溯至2020年9月1日

## 🔄 数据更新计划

由于数据采集涉及隐私保护和伦理审查，本数据集暂不计划定期更新。

如有研究需要，可联系数据维护团队申请最新数据。

## 📧 联系方式

**数据集维护团队：**
- Email: data-team@university.edu.cn
- GitHub Issues: [提交问题](https://github.com/YOUR_USERNAME/campus-secondhand-dataset/issues)

**合作与咨询：**
如需数据合作或有任何疑问，欢迎通过上述方式联系。

---

**最后更新时间：** 2024年6月30日  
**文档版本：** v1.0

